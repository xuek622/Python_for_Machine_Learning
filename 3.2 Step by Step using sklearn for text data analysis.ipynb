{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/NWEA_logo.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:#ffd800' > Step by Step Scikit-learn working with Text Data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ffd800'> A Machine Learning Problem of Classification </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"figures/fig8_imbd.png\" width=\"300\"> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will build a model that automatically classifies text as either having a positive or negative sentiment in IMDB.\n",
    "\n",
    "IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ffd800'> How to Get the Data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "https://github.com/nas5w/imdb-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ffd800'> Load the Data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'>  Step 1. load json file into python </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = './Data/reviews.json'\n",
    "\n",
    "with open(file_name) as json_file:\n",
    "    reviews = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#ffd800'> Sample Size </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#ffd800'> Raw data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'t': \"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\",\n",
       "  's': 0},\n",
       " {'t': \"This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and Ice Cube, who've each proven many times over that they are capable of acting, and acting well. Don't bother with this one, go see New Jack City, Ricochet or watch New York Undercover for Ice-T, or Boyz n the Hood, Higher Learning or Friday for Ice Cube and see the real deal. Ice-T's horribly cliched dialogue alone makes this film grate at the teeth, and I'm still wondering what the heck Bill Paxton was doing in this film? And why the heck does he always play the exact same character? From Aliens onward, every film I've seen with Bill Paxton has him playing the exact same irritating character, and at least in Aliens his character died, which made it somewhat gratifying...<br /><br />Overall, this is second-rate action trash. There are countless better films to see, and if you really want to see this one, watch Judgement Night, which is practically a carbon copy but has better acting and a better script. The only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing, which comes close to making up for the horrible film itself - but not quite. 4/10.\",\n",
       "  's': 0},\n",
       " {'t': \"First of all I hate those moronic rappers, who could'nt act if they had a gun pressed against their foreheads. All they do is curse and shoot each other and acting like clich√©'e version of gangsters.<br /><br />The movie doesn't take more than five minutes to explain what is going on before we're already at the warehouse There is not a single sympathetic character in this movie, except for the homeless guy, who is also the only one with half a brain.<br /><br />Bill Paxton and William Sadler are both hill billies and Sadlers character is just as much a villain as the gangsters. I did'nt like him right from the start.<br /><br />The movie is filled with pointless violence and Walter Hills specialty: people falling through windows with glass flying everywhere. There is pretty much no plot and it is a big problem when you root for no-one. Everybody dies, except from Paxton and the homeless guy and everybody get what they deserve.<br /><br />The only two black people that can act is the homeless guy and the junkie but they're actors by profession, not annoying ugly brain dead rappers.<br /><br />Stay away from this crap and watch 48 hours 1 and 2 instead. At lest they have characters you care about, a sense of humor and nothing but real actors in the cast.\",\n",
       "  's': 0},\n",
       " {'t': \"Not even the Beatles could write songs everyone liked, and although Walter Hill is no mop-top he's second to none when it comes to thought provoking action movies. The nineties came and social platforms were changing in music and film, the emergence of the Rapper turned movie star was in full swing, the acting took a back seat to each man's overpowering regional accent and transparent acting. This was one of the many ice-t movies i saw as a kid and loved, only to watch them later and cringe. Bill Paxton and William Sadler are firemen with basic lives until a burning building tenant about to go up in flames hands over a map with gold implications. I hand it to Walter for quickly and neatly setting up the main characters and location. But i fault everyone involved for turning out Lame-o performances. Ice-t and cube must have been red hot at this time, and while I've enjoyed both their careers as rappers, in my opinion they fell flat in this movie. It's about ninety minutes of one guy ridiculously turning his back on the other guy to the point you find yourself locked in multiple states of disbelief. Now this is a movie, its not a documentary so i wont waste my time recounting all the stupid plot twists in this movie, but there were many, and they led nowhere. I got the feeling watching this that everyone on set was sord of confused and just playing things off the cuff. There are two things i still enjoy about it, one involves a scene with a needle and the other is Sadler's huge 45 pistol. Bottom line this movie is like domino's pizza. Yeah ill eat it if I'm hungry and i don't feel like cooking, But I'm well aware it tastes like crap. 3 stars, meh.\",\n",
       "  's': 0},\n",
       " {'t': \"Brass pictures (movies is not a fitting word for them) really are somewhat brassy. Their alluring visual qualities are reminiscent of expensive high class TV commercials. But unfortunately Brass pictures are feature films with the pretense of wanting to entertain viewers for over two hours! In this they fail miserably, their undeniable, but rather soft and flabby than steamy, erotic qualities non withstanding.<br /><br />Senso '45 is a remake of a film by Luchino Visconti with the same title and Alida Valli and Farley Granger in the lead. The original tells a story of senseless love and lust in and around Venice during the Italian wars of independence. Brass moved the action from the 19th into the 20th century, 1945 to be exact, so there are Mussolini murals, men in black shirts, German uniforms or the tattered garb of the partisans. But it is just window dressing, the historic context is completely negligible.<br /><br />Anna Galiena plays the attractive aristocratic woman who falls for the amoral SS guy who always puts on too much lipstick. She is an attractive, versatile, well trained Italian actress and clearly above the material. Her wide range of facial expressions (signalling boredom, loathing, delight, fear, hate ... and ecstasy) are the best reason to watch this picture and worth two stars. She endures this basically trashy stuff with an astonishing amount of dignity. I wish some really good parts come along for her. She really deserves it.\",\n",
       "  's': 0}]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'>  Step 2. convert to dataframe </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "0      Once again Mr. Costner has dragged out a movie...          0\n",
       "1      This is an example of why the majority of acti...          0\n",
       "2      First of all I hate those moronic rappers, who...          0\n",
       "3      Not even the Beatles could write songs everyon...          0\n",
       "4      Brass pictures (movies is not a fitting word f...          0\n",
       "...                                                  ...        ...\n",
       "49995  Seeing as the vote average was pretty low, and...          1\n",
       "49996  The plot had some wretched, unbelievable twist...          1\n",
       "49997  I am amazed at how this movie(and most others ...          1\n",
       "49998  A Christmas Together actually came before my t...          1\n",
       "49999  Working-class romantic drama from director Mar...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "reviews = pd.DataFrame(reviews)\n",
    "reviews.columns = ['text', 'sentiment']\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "index_neg = np.random.randint(0, 24999, size = 500)\n",
    "index_pos = np.random.randint(25000, 49999, size = 500)\n",
    "reviews_neg = reviews.iloc[index_neg, :]\n",
    "reviews_pos = reviews.iloc[index_pos, :]\n",
    "reviews_sub = pd.concat([reviews_neg, reviews_pos], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tromaville High has become an amoral wasteland...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It just seems bizarre that someone read this s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normally I'm not motivated to write reviews. B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is deeply idiotic. A man wants reve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well the reason for seeing it in the cinema wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Well, after long anticipation after seeing a f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>In April 1947, New York City faced an epidemic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>In the early 1970s, many of us who had embrace...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>While the \"date doctor\" concept is the one thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This is such a fun and funny movie. Highly ent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  sentiment\n",
       "0    Tromaville High has become an amoral wasteland...          0\n",
       "1    It just seems bizarre that someone read this s...          0\n",
       "2    Normally I'm not motivated to write reviews. B...          0\n",
       "3    This movie is deeply idiotic. A man wants reve...          0\n",
       "4    Well the reason for seeing it in the cinema wa...          0\n",
       "..                                                 ...        ...\n",
       "995  Well, after long anticipation after seeing a f...          1\n",
       "996  In April 1947, New York City faced an epidemic...          1\n",
       "997  In the early 1970s, many of us who had embrace...          1\n",
       "998  While the \"date doctor\" concept is the one thi...          1\n",
       "999  This is such a fun and funny movie. Highly ent...          1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sub.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ffd800'> Data Preprocessing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Split data to training set and testing set </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    401\n",
       "0    399\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(reviews_sub, test_size=0.2, random_state=123)\n",
    "train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    400\n",
       "0    400\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(reviews_sub, test_size=0.2, \n",
    "                                       random_state=123, \n",
    "                                       stratify=reviews_sub['sentiment'])\n",
    "train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was praised to be a fast paced screwball comedy and the best German movie of the year, so I gave it a try, even though I\\'ve already seen some films by Dani Levy - or at least parts of them.<br /><br />I got what I had expected: no comedy at all, unless you think that heart attacks are funny. It\\'s a fine example of sloppy screen writing, with an implausible plot and characters, loaded with clich√©s that might be true, but surely are not funny either.<br /><br />The most annoying character is that of Zucker\\'s wife, played by Hannelore Elsner. She has to behave incredibly strange to keep the plot moving. For example: She doesn\\'t know a single thing about Judaism, but by reasons most likely unknown to even herself she gets the idea to play the charade that she and her family are Jewish laws obeying Jews for her husband\\'s family, who really are, and of the very orthodox and self-righteous variety. To make it a bit more complicated, she invites the four of them to stay at her city flat, because they arrive from Frankfurt in Berlin without having booked their hotels in advance, something no 60 years old business man, actually no grown-up German would ever do. This gives the viewer a lot to swallow, but still fails to produce any jokes.<br /><br />Zucker and his brother Samuel haven\\'t seen each other for forty years, but it turns out that his daughter - now a lesbian - and Samuel\\'s son - now a militant orthodox - were once lovers, and he\\'s HER daughter\\'s father. Samuel\\'s daughter - a nympho - goes after Zucker\\'s gay son. Is this supposed to be a somehow humorous parody of Jewish incestuous tendencies? Probably it\\'s just a thoughtless way to add some \"love action turbulence\" every screwball comedy needs. And of course is also fails to produce any jokes.<br /><br />The praise for this movie is purely political. Therefore only people who enjoy watching movies that are supposed to be \"politically important\" will enjoy this one - even though \"Alles auf Zucker!\" quite clearly has no importance of any kind.<br /><br />For all the rest: Don\\'t watch it without a \"Fast forward\"-option. I really missed it.'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.array([x.text for _, x in train.iterrows()])\n",
    "train_y = np.array([x.sentiment for _, x in train.iterrows()])\n",
    "\n",
    "test_x = np.array([x.text for _, x in test.iterrows()])\n",
    "test_y = np.array([x.sentiment for _, x in test.iterrows()])\n",
    "\n",
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Turn text content into numerical feature vector </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#ffd800'> The most intuitive method: Bags of words </span>\n",
    "https://en.wikipedia.org/wiki/Bag-of-words_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#ffd800'> Text preprocessing </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 15553) (200, 15553)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorize = CountVectorizer()\n",
    "\n",
    "vectorize.fit(train_x)\n",
    "train_x_vectors = vectorize.transform(train_x)\n",
    "\n",
    "# X_train_counts = count_vect.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorize.transform(test_x)\n",
    "print(train_x_vectors.shape, test_x_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One of my favorite villains, the Evil Princess is just the perfect villain for this movie. Full of space travel, horses, diamonds, mystical characters, colorful backgrounds, evil characters, etc etc. Very bright, full of action, you will not get bored. Great movie!'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 327)\t1\n",
      "  (0, 1178)\t1\n",
      "  (0, 1732)\t1\n",
      "  (0, 1852)\t1\n",
      "  (0, 2363)\t2\n",
      "  (0, 2743)\t1\n",
      "  (0, 3895)\t1\n",
      "  (0, 4822)\t2\n",
      "  (0, 4864)\t2\n",
      "  (0, 5183)\t1\n",
      "  (0, 5512)\t1\n",
      "  (0, 5695)\t2\n",
      "  (0, 5867)\t1\n",
      "  (0, 6093)\t1\n",
      "  (0, 6712)\t1\n",
      "  (0, 7383)\t1\n",
      "  (0, 7621)\t1\n",
      "  (0, 9137)\t2\n",
      "  (0, 9222)\t1\n",
      "  (0, 9233)\t1\n",
      "  (0, 9493)\t1\n",
      "  (0, 9612)\t3\n",
      "  (0, 9664)\t1\n",
      "  (0, 10124)\t1\n",
      "  (0, 10666)\t1\n",
      "  (0, 12899)\t1\n",
      "  (0, 13886)\t2\n",
      "  (0, 13937)\t1\n",
      "  (0, 14233)\t1\n",
      "  (0, 14830)\t1\n",
      "  (0, 14882)\t1\n",
      "  (0, 14884)\t1\n",
      "  (0, 15257)\t1\n",
      "  (0, 15491)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_x_vectors[1])\n",
    "# print(train_x_vectors[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5183"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get('favorite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15553"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_vectors\n",
    "# train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ffd800'> Classification </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> SVM </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Random Forest </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "clf_rfc = RandomForestClassifier()\n",
    "clf_rfc.fit(train_x_vectors, train_y)\n",
    "clf_rfc.predict(test_x_vectors[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Logistic Regression </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lgr = LogisticRegression(max_iter=10000)\n",
    "clf_lgr.fit(train_x_vectors, train_y)\n",
    "clf_lgr.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Naive Bayes </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.toarray(), train_y)\n",
    "clf_gnb.predict(test_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Nearest Neighbors Classification </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_knn.fit(train_x_vectors, train_y)\n",
    "clf_knn.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ffd800'> Model Evaluation </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Simple score </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM mean accuracy: 0.77\n",
      "Random Forest mean accuracy: 0.795\n",
      "Logistic Regression mean accuracy: 0.81\n",
      "Naive Bayes mean accuracy: 0.62\n",
      "kNN mean accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "print('SVM mean accuracy: ' + str(clf_svm.score(test_x_vectors, test_y)))\n",
    "print('Random Forest mean accuracy: ' + str(clf_rfc.score(test_x_vectors, test_y)))\n",
    "print('Logistic Regression mean accuracy: ' + str(clf_lgr.score(test_x_vectors, test_y)))\n",
    "print('Naive Bayes mean accuracy: ' + str(clf_gnb.score(test_x_vectors.toarray(), test_y)))\n",
    "print('kNN mean accuracy: ' + str(clf_knn.score(test_x_vectors, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> F1 score </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM f1 score: 0.780952380952381\n",
      "Random Forest f1 score: 0.8110599078341014\n",
      "Logistic Regression f1 score: 0.819047619047619\n",
      "Naive Bayes f1 score: 0.6082474226804124\n",
      "kNN mean f1 score: 0.6272727272727272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('SVM f1 score: ' + str(f1_score(test_y, clf_svm.predict(test_x_vectors))))\n",
    "print('Random Forest f1 score: ' + str(f1_score(test_y, clf_rfc.predict(test_x_vectors))))\n",
    "print('Logistic Regression f1 score: ' + str(f1_score(test_y, clf_lgr.predict(test_x_vectors))))\n",
    "print('Naive Bayes f1 score: ' + str(f1_score(test_y, clf_gnb.predict(test_x_vectors.toarray()))))\n",
    "print('kNN mean f1 score: ' + str(f1_score(test_y, clf_knn.predict(test_x_vectors))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Truing our models using Grid Search </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rfc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{'bootstrap': [True, False],\n",
       "                          'criterion': ['gini', 'entropy'],\n",
       "                          'n_estimators': [50, 100, 200]}],\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [50, 100, 200], 'bootstrap': [True, False], 'criterion': ['gini', 'entropy']},\n",
    "]\n",
    "\n",
    "clf_rfc_GS = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(clf_rfc_GS, param_grid, cv=5,  return_train_score=True)\n",
    "\n",
    "grid_search.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, criterion='entropy', n_estimators=200)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mean accuracy: 0.795\n",
      "Tuned Random Forest mean accuracy: 0.825\n",
      "Random Forest f1 score: 0.8110599078341014\n",
      "Tuned Random Forest f1 score: 0.8372093023255814\n"
     ]
    }
   ],
   "source": [
    "clf_rfc_GS_best = grid_search.best_estimator_\n",
    "clf_rfc_GS_best.fit(train_x_vectors, train_y)\n",
    "print('Random Forest mean accuracy: ' + str(clf_rfc.score(test_x_vectors, test_y)))\n",
    "print('Tuned Random Forest mean accuracy: ' + str(clf_rfc_GS_best.score(test_x_vectors, test_y)))\n",
    "print('Random Forest f1 score: ' + str(f1_score(test_y, clf_rfc.predict(test_x_vectors))))\n",
    "print('Tuned Random Forest f1 score: ' + str(f1_score(test_y, clf_rfc_GS_best.predict(test_x_vectors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Saving and Loading our Model using Pickle</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save our best models using pickle package\n",
    "import pickle, os\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf_rfc_GS_best, open(os.path.join('./models', filename), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372093023255814\n"
     ]
    }
   ],
   "source": [
    "## load the model from disk\n",
    "loaded_clf_rfc = pickle.load(open(os.path.join('./models', filename), 'rb'))\n",
    "print(f1_score(test_y, loaded_clf_rfc.predict(test_x_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ffd800'> A Multiple Classification Problem </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Data: 'Twenty Newsgroups' </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://qwone.com/~jason/20Newsgroups/\n",
    "\n",
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper ‚ÄúNewsweeder: Learning to filter netnews,‚Äù though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Load Data </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['rec.autos', 'sci.med', 'comp.graphics', 'misc.forsale']\n",
    "\n",
    "train_twenty = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=123)\n",
    "test_twenty = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357 4\n",
      "1571 4\n"
     ]
    }
   ],
   "source": [
    "# show the sample size\n",
    "print(len(train_twenty.data), len(train_twenty.target_names))\n",
    "print(len(test_twenty.data), len(test_twenty.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'rec.autos',\n",
       " 'rec.autos',\n",
       " 'comp.graphics',\n",
       " 'sci.med',\n",
       " 'misc.forsale',\n",
       " 'comp.graphics',\n",
       " 'rec.autos',\n",
       " 'misc.forsale',\n",
       " 'misc.forsale']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the first 10 samples' labels \n",
    "[train_twenty.target_names[t] for t in train_twenty.target[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Data Preprocessing </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_twenty.data)\n",
    "train_y = train_twenty.target\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_twenty.data)\n",
    "test_y = test_twenty.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the occurrence to frequencies\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(train_x_vectors)\n",
    "\n",
    "train_x_tf_idf = tf_transformer.transform(train_x_vectors)\n",
    "test_x_tf_idf = tf_transformer.transform(test_x_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Train a Random Forest Classifier </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rfc = RandomForestClassifier().fit(train_x_tf_idf, train_y)\n",
    "pred_y = clf_rfc.predict(test_x_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "comp.graphics       0.71      0.88      0.79       389\n",
      " misc.forsale       0.88      0.93      0.90       390\n",
      "    rec.autos       0.83      0.84      0.83       396\n",
      "      sci.med       0.94      0.65      0.77       396\n",
      "\n",
      "     accuracy                           0.83      1571\n",
      "    macro avg       0.84      0.83      0.82      1571\n",
      " weighted avg       0.84      0.83      0.82      1571\n",
      "\n",
      "[[343  17  18  11]\n",
      " [ 12 364  12   2]\n",
      " [ 42  18 333   3]\n",
      " [ 83  16  39 258]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation the classifier\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(test_y, pred_y, target_names=test_twenty.target_names))\n",
    "print(metrics.confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Tuning our Model</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{'bootstrap': [True, False],\n",
       "                          'criterion': ['gini', 'entropy'],\n",
       "                          'n_estimators': [50, 100, 200]}],\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    {'n_estimators': [50, 100, 200], 'bootstrap': [True, False], 'criterion': ['gini', 'entropy']},\n",
    "]\n",
    "\n",
    "clf_rfc_GS = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(clf_rfc_GS, param_grid, cv=5,  return_train_score=True)\n",
    "grid_search.fit(train_x_tf_idf, train_y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "comp.graphics       0.78      0.93      0.85       389\n",
      " misc.forsale       0.90      0.94      0.92       390\n",
      "    rec.autos       0.89      0.88      0.88       396\n",
      "      sci.med       0.94      0.73      0.83       396\n",
      "\n",
      "     accuracy                           0.87      1571\n",
      "    macro avg       0.88      0.87      0.87      1571\n",
      " weighted avg       0.88      0.87      0.87      1571\n",
      "\n",
      "[[360   8   9  12]\n",
      " [ 14 365   9   2]\n",
      " [ 28  15 350   3]\n",
      " [ 61  17  27 291]]\n"
     ]
    }
   ],
   "source": [
    "clf_rfc_best = grid_search.best_estimator_\n",
    "pred_y = clf_rfc_best.predict(test_x_tf_idf)\n",
    "\n",
    "print(metrics.classification_report(test_y, pred_y, target_names=test_twenty.target_names))\n",
    "print(metrics.confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ffd800'> Pipeline in Sklearn </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['rec.autos', 'sci.med', 'comp.graphics', 'misc.forsale']\n",
    "\n",
    "train_twenty = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=123)\n",
    "test_twenty = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> First pipeline for data preprocessing </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the preprocessing fucntion by combining two functions in a pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocessing = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                          ('tfidf',  TfidfTransformer(use_idf=True))])\n",
    "\n",
    "train_x_tf_idf = preprocessing.fit_transform(train_twenty.data)\n",
    "train_y = train_twenty.target\n",
    "\n",
    "test_y_tf_idf = preprocessing.transform(test_twenty.data)\n",
    "test_y = test_twenty.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Pipeline can be contained in another pipeline </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data preprocessing with classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([('features', preprocessing), \n",
    "                     ('classifier', RandomForestClassifier())])\n",
    "\n",
    "pipeline.fit(train_twenty.data, train_twenty.target)\n",
    "pred_y = pipeline.predict(test_twenty.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#ffd800'> Cross Validation To Find The Best Pipeline </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'features', 'classifier', 'features__memory', 'features__steps', 'features__verbose', 'features__vectorizer', 'features__tfidf', 'features__vectorizer__analyzer', 'features__vectorizer__binary', 'features__vectorizer__decode_error', 'features__vectorizer__dtype', 'features__vectorizer__encoding', 'features__vectorizer__input', 'features__vectorizer__lowercase', 'features__vectorizer__max_df', 'features__vectorizer__max_features', 'features__vectorizer__min_df', 'features__vectorizer__ngram_range', 'features__vectorizer__preprocessor', 'features__vectorizer__stop_words', 'features__vectorizer__strip_accents', 'features__vectorizer__token_pattern', 'features__vectorizer__tokenizer', 'features__vectorizer__vocabulary', 'features__tfidf__norm', 'features__tfidf__smooth_idf', 'features__tfidf__sublinear_tf', 'features__tfidf__use_idf', 'classifier__bootstrap', 'classifier__ccp_alpha', 'classifier__class_weight', 'classifier__criterion', 'classifier__max_depth', 'classifier__max_features', 'classifier__max_leaf_nodes', 'classifier__max_samples', 'classifier__min_impurity_decrease', 'classifier__min_impurity_split', 'classifier__min_samples_leaf', 'classifier__min_samples_split', 'classifier__min_weight_fraction_leaf', 'classifier__n_estimators', 'classifier__n_jobs', 'classifier__oob_score', 'classifier__random_state', 'classifier__verbose', 'classifier__warm_start'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the hyperparameters of pipeline\n",
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__bootstrap': False,\n",
       " 'classifier__criterion': 'gini',\n",
       " 'classifier__n_estimators': 100}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameters = {'classifier__n_estimators': [50, 100, 200],\n",
    "                   'classifier__bootstrap': [True, False],\n",
    "                   'classifier__criterion': ['gini', 'entropy']}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, hyperparameters, cv=5)\n",
    "grid_search.fit(train_twenty.data, train_twenty.target)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "comp.graphics       0.76      0.92      0.83       389\n",
      " misc.forsale       0.91      0.94      0.93       390\n",
      "    rec.autos       0.89      0.86      0.88       396\n",
      "      sci.med       0.93      0.73      0.82       396\n",
      "\n",
      "     accuracy                           0.86      1571\n",
      "    macro avg       0.87      0.86      0.86      1571\n",
      " weighted avg       0.87      0.86      0.86      1571\n",
      "\n",
      "[[359   7  11  12]\n",
      " [ 14 367   5   4]\n",
      " [ 34  14 341   7]\n",
      " [ 66  15  25 290]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "clf_rfc_best = grid_search.best_estimator_\n",
    "\n",
    "pred_y = clf_rfc_best.predict(test_twenty.data)\n",
    "print(metrics.classification_report(test_twenty.target, pred_y, target_names=test_twenty.target_names))\n",
    "print(metrics.confusion_matrix(test_twenty.target, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
